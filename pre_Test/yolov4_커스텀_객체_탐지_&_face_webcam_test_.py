# -*- coding: utf-8 -*-
"""YOLOv4 커스텀 객체 탐지 & face webcam test .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hECGXJB2ep5jJJcMrTR9rXhMBHcgYG6E
"""

!git clone https://github.com/AlexeyAB/darknet

# Commented out IPython magic to ensure Python compatibility.
# %cd darknet

!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile

!/usr/local/cuda/bin/nvcc --version

#yolov4 설치
!make

!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights

# Commented out IPython magic to ensure Python compatibility.
# define helper functions
def imShow(path):
  import cv2
  import matplotlib.pyplot as plt
#   %matplotlib inline

  image = cv2.imread(path)
  height, width = image.shape[:2]
  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)

  fig = plt.gcf()
  fig.set_size_inches(18, 10)
  plt.axis("off")
  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))
  plt.show()

# use this to upload files
def upload():
  from google.colab import files
  uploaded = files.upload() 
  for name, data in uploaded.items():
    with open(name, 'wb') as f:
      f.write(data)
      print ('saved file', name)

# use this to download a file  
def download(path):
  from google.colab import files
  files.download(path)

# run darknet with YOLOv4 on face_0.jpg (얼굴 정면)
!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights ../face_0.jpg
imShow('predictions.jpg')

"""## face_recognition 으로 웹캠 test"""

!pip install face_recognition

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline 
import face_recognition
import cv2
import matplotlib.patches as patches
from IPython.display import clear_output
from matplotlib.pyplot import imshow
import matplotlib.pylab as plt

video_capture = cv2.VideoCapture("/content/001.mp4")
 
frame_count = 0

while video_capture.isOpened():    
    # Grab a single frame of video
    ret, frame = video_capture.read()
    if not ret:
        video_capture.release()
        break

    # 25 프레임마다 얼굴을 인식하도록 설정.
    frame_count += 1
    if frame_count % 25 == 0:    
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # Display video frame
        title("Input Stream")
        plt.imshow(frame)        

        # Find all the faces and face encodings in the current frame of video

        rgb_frame = frame[:, :, ::-1]
        face_locations = face_recognition.face_locations(rgb_frame)

        # If faces were found, we will mark it on frame with blue dots
        for face_location in face_locations:        
            plt.plot(face_location[1], face_location[0], 'bo')
            plt.plot(face_location[1], face_location[2], 'bo')
            plt.plot(face_location[3], face_location[2], 'bo')
            plt.plot(face_location[3], face_location[0], 'bo')

        plt.show() 
        # ... and hold it until a new frame appears
        clear_output(wait=True)

